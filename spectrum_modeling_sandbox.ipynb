{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd949251-18d9-40aa-b101-abf5fdba88c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examining FCC auction data files in ./data\n",
      "Successfully loaded headers from results_auction108.csv\n",
      "Successfully loaded headers from bidder_status_auction102.csv\n",
      "Successfully loaded headers from bidder_prs_auction108.csv\n",
      "Successfully loaded headers from product_status_auction108.csv\n",
      "Successfully loaded headers from results_auction102.csv\n",
      "Successfully loaded headers from product_status_auction102.csv\n",
      "Successfully loaded headers from markets_auction102.csv\n",
      "Successfully loaded headers from market_auction108.csv\n",
      "Successfully loaded headers from unassigned_licenses_auction108.csv\n",
      "\n",
      "File: results_auction108.csv\n",
      "Number of columns: 13\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. round\n",
      "  3. bidder\n",
      "  4. frn\n",
      "  5. market\n",
      "  6. market_name\n",
      "  7. category\n",
      "  8. processed_demand\n",
      "  9. fully_processed_flag\n",
      "  10. processed_demand_detail\n",
      "  11. bidding_units\n",
      "  12. aggregate_demand\n",
      "  13. posted_price\n",
      "\n",
      "File: bidder_status_auction102.csv\n",
      "Number of columns: 22\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. round\n",
      "  3. bidder\n",
      "  4. frn\n",
      "  5. bidding_credit_pct\n",
      "  6. bidding_credit_type\n",
      "  7. eligibility\n",
      "  8. required_activity\n",
      "  9. activity\n",
      "  10. req_commitment\n",
      "  11. req_commitment_discount_capped\n",
      "  12. req_net_commitment\n",
      "  13. req_commitment_discount_uncapped\n",
      "  14. req_commitment_discount_uncapped_small\n",
      "  15. processed_activity\n",
      "  16. commitment\n",
      "  17. commitment_discount_capped\n",
      "  18. net_commitment\n",
      "  19. commitment_discount_uncapped\n",
      "  20. commitment_discount_uncapped_small\n",
      "  21. next_round_eligibility\n",
      "  22. next_round_required_activity\n",
      "\n",
      "File: bidder_prs_auction108.csv\n",
      "Number of columns: 6\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. bidder\n",
      "  3. frn\n",
      "  4. eligibility\n",
      "  5. bidding_credit\n",
      "  6. bidding_credit_type\n",
      "\n",
      "File: product_status_auction108.csv\n",
      "Number of columns: 13\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. round\n",
      "  3. market\n",
      "  4. market_name\n",
      "  5. category\n",
      "  6. small_market_indicator\n",
      "  7. population\n",
      "  8. bidding_units\n",
      "  9. start_of_round_price\n",
      "  10. clock_price\n",
      "  11. aggregate_demand\n",
      "  12. posted_price\n",
      "  13. next_round_clock_price\n",
      "\n",
      "File: results_auction102.csv\n",
      "Number of columns: 12\n",
      "Headers:\n",
      "  1. round\n",
      "  2. market_number\n",
      "  3. market_name\n",
      "  4. category\n",
      "  5. bidder\n",
      "  6. frn\n",
      "  7. processed_demand\n",
      "  8. processed_demand_flag\n",
      "  9. processed_demand_detail\n",
      "  10. supply\n",
      "  11. aggregate_demand\n",
      "  12. posted_price\n",
      "\n",
      "File: product_status_auction102.csv\n",
      "Number of columns: 13\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. round\n",
      "  3. market_number\n",
      "  4. market_name\n",
      "  5. category\n",
      "  6. round_opening_price\n",
      "  7. clock_price\n",
      "  8. aggregate_demand\n",
      "  9. posted_price\n",
      "  10. next_round_clock_price\n",
      "  11. bidding_units\n",
      "  12. supply\n",
      "  13. population\n",
      "\n",
      "File: markets_auction102.csv\n",
      "Number of columns: 6\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. market_number\n",
      "  3. market_description\n",
      "  4. market_population\n",
      "  5. bidding_units\n",
      "  6. small_market_indicator\n",
      "\n",
      "File: market_auction108.csv\n",
      "Number of columns: 6\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. market\n",
      "  3. market_name\n",
      "  4. census_id\n",
      "  5. population\n",
      "  6. small_market_indicator\n",
      "\n",
      "File: unassigned_licenses_auction108.csv\n",
      "Number of columns: 5\n",
      "Headers:\n",
      "  1. auction_id\n",
      "  2. license\n",
      "  3. market\n",
      "  4. market_name\n",
      "  5. category\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def load_and_examine_fcc_data(data_folder_path):\n",
    "    \"\"\"\n",
    "    Loads FCC auction data files from a specified folder and examines their headers.\n",
    "    \n",
    "    Args:\n",
    "        data_folder_path (str): Path to the folder containing FCC auction data files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mapping filenames to their respective headers\n",
    "    \"\"\"\n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(data_folder_path):\n",
    "        raise FileNotFoundError(f\"The folder {data_folder_path} does not exist\")\n",
    "    \n",
    "    # Get all CSV files in the folder\n",
    "    file_paths = glob.glob(os.path.join(data_folder_path, \"*.csv\"))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(f\"No CSV files found in {data_folder_path}\")\n",
    "        return {}\n",
    "    \n",
    "    headers_by_file = {}\n",
    "    \n",
    "    # Load each file and examine headers\n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        try:\n",
    "            # Read just the header row to save memory\n",
    "            df = pd.read_csv(file_path, nrows=0)\n",
    "            headers = list(df.columns)\n",
    "            headers_by_file[file_name] = headers\n",
    "            print(f\"Successfully loaded headers from {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_name}: {str(e)}\")\n",
    "    \n",
    "    return headers_by_file\n",
    "\n",
    "def main():\n",
    "    # Path to your data folder - update this to your specific path\n",
    "    data_folder = \"./data\"\n",
    "    \n",
    "    print(f\"Examining FCC auction data files in {data_folder}\")\n",
    "    headers_dict = load_and_examine_fcc_data(data_folder)\n",
    "    \n",
    "    # Display headers for each file\n",
    "    for file_name, headers in headers_dict.items():\n",
    "        print(f\"\\nFile: {file_name}\")\n",
    "        print(f\"Number of columns: {len(headers)}\")\n",
    "        print(\"Headers:\")\n",
    "        for i, header in enumerate(headers, 1):\n",
    "            print(f\"  {i}. {header}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc05f8d6-8cfe-4ff9-bf21-d9f8246ff228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "class FCCAuctionDataAnalyzer:\n",
    "    \"\"\"\n",
    "    A class for analyzing FCC auction data, particularly for Auction 108 (2.5 GHz).\n",
    "    This analyzer loads, processes, and helps visualize auction data to prepare\n",
    "    for predictive modeling of spectrum auction prices.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_folder_path):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with the path to the data folder.\n",
    "        \n",
    "        Args:\n",
    "            data_folder_path (str): Path to the folder containing FCC auction data files\n",
    "        \"\"\"\n",
    "        self.data_folder = Path(data_folder_path)\n",
    "        self.file_paths = {}\n",
    "        self.data = {}\n",
    "        self.file_patterns = {\n",
    "            \"announcements\": \"announcements*.csv\",\n",
    "            \"round_summary\": \"round_summary*.csv\",\n",
    "            \"bids\": \"bids*.csv\",\n",
    "            \"results\": \"results*.csv\",\n",
    "            \"results_by_license\": \"results_by_license*.csv\",\n",
    "            \"unassigned_licenses\": \"unassigned_licenses*.csv\",\n",
    "            \"product_status\": \"product_status*.csv\",\n",
    "            \"bidder_status\": \"bidder_status*.csv\",\n",
    "            \"bidder_markets\": \"bidder_markets*.csv\",\n",
    "            \"bidders\": \"bidders*.csv\",\n",
    "            \"markets\": \"markets*.csv\"\n",
    "        }\n",
    "        \n",
    "        # Check if the folder exists\n",
    "        if not os.path.exists(data_folder_path):\n",
    "            raise FileNotFoundError(f\"The folder {data_folder_path} does not exist\")\n",
    "        \n",
    "        # Discover available data files\n",
    "        self._discover_files()\n",
    "    \n",
    "    def _discover_files(self):\n",
    "        \"\"\"\n",
    "        Discover all available FCC auction data files in the data folder.\n",
    "        \"\"\"\n",
    "        for file_type, pattern in self.file_patterns.items():\n",
    "            matching_files = list(self.data_folder.glob(pattern))\n",
    "            if matching_files:\n",
    "                self.file_paths[file_type] = matching_files\n",
    "    \n",
    "    def list_available_files(self):\n",
    "        \"\"\"\n",
    "        List all available data files found in the data folder.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary of file types and their paths\n",
    "        \"\"\"\n",
    "        available_files = {}\n",
    "        for file_type, paths in self.file_paths.items():\n",
    "            available_files[file_type] = [path.name for path in paths]\n",
    "        \n",
    "        return available_files\n",
    "    \n",
    "    def load_data(self, file_types=None):\n",
    "        \"\"\"\n",
    "        Load specified data files into memory.\n",
    "        \n",
    "        Args:\n",
    "            file_types (list, optional): List of file types to load. \n",
    "                                         If None, loads all available files.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary of loaded data frames\n",
    "        \"\"\"\n",
    "        if file_types is None:\n",
    "            file_types = list(self.file_paths.keys())\n",
    "        \n",
    "        for file_type in file_types:\n",
    "            if file_type in self.file_paths:\n",
    "                try:\n",
    "                    for path in self.file_paths[file_type]:\n",
    "                        # Handle date parsing for time columns\n",
    "                        if file_type == \"announcements\" or file_type == \"round_summary\":\n",
    "                            self.data[file_type] = pd.read_csv(\n",
    "                                path, \n",
    "                                parse_dates=[\"announcement_time\" if file_type == \"announcements\" \n",
    "                                             else \"start_time\", \"end_time\"]\n",
    "                            )\n",
    "                        else:\n",
    "                            self.data[file_type] = pd.read_csv(path)\n",
    "                        \n",
    "                        print(f\"Successfully loaded {path.name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {file_type}: {str(e)}\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def display_file_info(self, file_types=None):\n",
    "        \"\"\"\n",
    "        Display basic information about loaded data files.\n",
    "        \n",
    "        Args:\n",
    "            file_types (list, optional): List of file types to display info for. \n",
    "                                         If None, displays info for all loaded files.\n",
    "        \"\"\"\n",
    "        if file_types is None:\n",
    "            file_types = list(self.data.keys())\n",
    "        \n",
    "        for file_type in file_types:\n",
    "            if file_type in self.data:\n",
    "                df = self.data[file_type]\n",
    "                print(f\"\\n=== {file_type.upper()} ===\")\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Columns: {', '.join(df.columns)}\")\n",
    "                print(\"\\nSample data:\")\n",
    "                print(df.head(3))\n",
    "                print(\"\\nData types:\")\n",
    "                print(df.dtypes)\n",
    "    \n",
    "    def get_column_descriptions(self, file_type):\n",
    "        \"\"\"\n",
    "        Get descriptions of columns for a specific file type based on documentation.\n",
    "        \n",
    "        Args:\n",
    "            file_type (str): The type of file to get column descriptions for\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary mapping column names to their descriptions\n",
    "        \"\"\"\n",
    "        # Column descriptions based on the provided documentation\n",
    "        descriptions = {\n",
    "            # Results by License file column descriptions\n",
    "            \"results_by_license\": {\n",
    "                \"auction_id\": \"The FCC auction number for the auction\",\n",
    "                \"license\": \"The combined license name\",\n",
    "                \"market\": \"The county ID\",\n",
    "                \"market_name\": \"The county name\",\n",
    "                \"category\": \"The license category (C1, C2, C3)\",\n",
    "                \"bidder\": \"Bidder name\",\n",
    "                \"frn\": \"The bidder's FCC Registration Number\",\n",
    "                \"bidding_credit_type\": \"Indicates the type of bidding credit for the bidder\",\n",
    "                \"bidding_credit\": \"The bidding credit percentage (0, 15, 25)\",\n",
    "                \"gross_license_price\": \"The gross price of the license\",\n",
    "                \"net_license_price\": \"The net price of the license after bidding credit discount\",\n",
    "                \"effective_bidding_credit\": \"Calculated as 100 times (1-(net_license_price/gross_license_price))\"\n",
    "            },\n",
    "            # Markets file column descriptions\n",
    "            \"markets\": {\n",
    "                \"auction_id\": \"The FCC auction number for the auction\",\n",
    "                \"market\": \"The county ID\",\n",
    "                \"market_name\": \"The county name\",\n",
    "                \"census_id\": \"The FIPS ID for the county\",\n",
    "                \"population\": \"Population of the county\",\n",
    "                \"small_market_indicator\": \"A flag indicating if the market is subject to the small market bidding credit cap\"\n",
    "            },\n",
    "            # Add other file types as needed...\n",
    "        }\n",
    "        \n",
    "        if file_type in descriptions:\n",
    "            return descriptions[file_type]\n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    def analyze_final_prices(self):\n",
    "        \"\"\"\n",
    "        Analyze the final prices from the results_by_license file.\n",
    "        \"\"\"\n",
    "        if \"results_by_license\" not in self.data:\n",
    "            print(\"Results by license data not loaded. Please load it first.\")\n",
    "            return\n",
    "        \n",
    "        df = self.data[\"results_by_license\"]\n",
    "        \n",
    "        # Basic price statistics\n",
    "        print(\"=== PRICE ANALYSIS ===\")\n",
    "        print(\"\\nGross License Price Statistics:\")\n",
    "        print(df['gross_license_price'].describe())\n",
    "        \n",
    "        # Price distribution by category\n",
    "        print(\"\\nGross License Price by Category:\")\n",
    "        print(df.groupby('category')['gross_license_price'].describe())\n",
    "        \n",
    "        # Create a price histogram\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df['gross_license_price'], bins=30)\n",
    "        plt.title('Distribution of Gross License Prices')\n",
    "        plt.xlabel('Price ($)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "        \n",
    "        # Create boxplot by category\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(x='category', y='gross_license_price', data=df)\n",
    "        plt.title('License Prices by Category')\n",
    "        plt.xlabel('License Category')\n",
    "        plt.ylabel('Gross Price ($)')\n",
    "        plt.show()\n",
    "    \n",
    "    def merge_price_and_market_data(self):\n",
    "        \"\"\"\n",
    "        Merge the results_by_license data with markets data to enable analysis of\n",
    "        price vs population and other market characteristics.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: Merged data with license prices and market characteristics\n",
    "        \"\"\"\n",
    "        if \"results_by_license\" not in self.data or \"markets\" not in self.data:\n",
    "            print(\"Required data not loaded. Please load results_by_license and markets data first.\")\n",
    "            return None\n",
    "        \n",
    "        # Merge the datasets\n",
    "        merged_df = pd.merge(\n",
    "            self.data[\"results_by_license\"],\n",
    "            self.data[\"markets\"],\n",
    "            on=[\"auction_id\", \"market\", \"market_name\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # Create price per population metric\n",
    "        merged_df['price_per_pop'] = merged_df['gross_license_price'] / merged_df['population']\n",
    "        \n",
    "        return merged_df\n",
    "    \n",
    "    def prepare_model_dataset(self):\n",
    "        \"\"\"\n",
    "        Prepare a dataset suitable for the random forest model to predict auction prices.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: Prepared dataset with features and target variable\n",
    "        \"\"\"\n",
    "        # First, merge price and market data\n",
    "        merged_df = self.merge_price_and_market_data()\n",
    "        if merged_df is None:\n",
    "            return None\n",
    "        \n",
    "        # Create additional features that might be useful for prediction\n",
    "        model_df = merged_df.copy()\n",
    "        \n",
    "        # Convert categorical variables to dummy variables\n",
    "        model_df = pd.get_dummies(model_df, columns=['category', 'small_market_indicator'])\n",
    "        \n",
    "        # Log transform the population (common in econometric models)\n",
    "        model_df['log_population'] = np.log1p(model_df['population'])\n",
    "        \n",
    "        # Define target variable\n",
    "        model_df['target_price'] = model_df['gross_license_price']\n",
    "        \n",
    "        # Select features for the model\n",
    "        feature_cols = [\n",
    "            'population', 'log_population', \n",
    "            'category_C1', 'category_C2', 'category_C3',\n",
    "            'small_market_indicator_Y', 'small_market_indicator_N'\n",
    "        ]\n",
    "        \n",
    "        # Return both the full dataset and a subset with just the features and target\n",
    "        model_features = model_df[feature_cols]\n",
    "        model_target = model_df['target_price']\n",
    "        \n",
    "        return {\n",
    "            'full_data': model_df,\n",
    "            'features': model_features,\n",
    "            'target': model_target\n",
    "        }\n",
    "\n",
    "def main():\n",
    "    # Update this path to your specific data folder location\n",
    "    data_folder = \"./data\"\n",
    "    \n",
    "    # Initialize the analyzer\n",
    "    analyzer = FCCAuctionDataAnalyzer(data_folder)\n",
    "    \n",
    "    # List available files\n",
    "    available_files = analyzer.list_available_files()\n",
    "    print(\"Available files:\")\n",
    "    for file_type, files in available_files.items():\n",
    "        print(f\"  {file_type}: {', '.join(files)}\")\n",
    "    \n",
    "    # Load all available data\n",
    "    analyzer.load_data()\n",
    "    \n",
    "    # Display information about loaded files\n",
    "    analyzer.display_file_info()\n",
    "    \n",
    "    # Analyze final prices (if results_by_license data is available)\n",
    "    if \"results_by_license\" in analyzer.data:\n",
    "        analyzer.analyze_final_prices()\n",
    "    \n",
    "    # Prepare dataset for modeling\n",
    "    model_data = analyzer.prepare_model_dataset()\n",
    "    if model_data is not None:\n",
    "        print(\"\\n=== MODEL DATASET PREVIEW ===\")\n",
    "        print(model_data['full_data'].head())\n",
    "        print(\"\\nFeatures shape:\", model_data['features'].shape)\n",
    "        print(\"Target shape:\", model_data['target'].shape)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
